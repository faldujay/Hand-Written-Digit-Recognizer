{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:21.487673Z",
     "iopub.status.busy": "2020-09-06T16:24:21.487053Z",
     "iopub.status.idle": "2020-09-06T16:24:21.494802Z",
     "shell.execute_reply": "2020-09-06T16:24:21.494119Z"
    },
    "papermill": {
     "duration": 0.021621,
     "end_time": "2020-09-06T16:24:21.494945",
     "exception": false,
     "start_time": "2020-09-06T16:24:21.473324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/test.csv\n",
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.006029,
     "end_time": "2020-09-06T16:24:21.508121",
     "exception": false,
     "start_time": "2020-09-06T16:24:21.502092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:21.528706Z",
     "iopub.status.busy": "2020-09-06T16:24:21.528020Z",
     "iopub.status.idle": "2020-09-06T16:24:26.890075Z",
     "shell.execute_reply": "2020-09-06T16:24:26.890564Z"
    },
    "papermill": {
     "duration": 5.376455,
     "end_time": "2020-09-06T16:24:26.890766",
     "exception": false,
     "start_time": "2020-09-06T16:24:21.514311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
    "df2 = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n",
    "\n",
    "print(df.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:27.001904Z",
     "iopub.status.busy": "2020-09-06T16:24:26.914736Z",
     "iopub.status.idle": "2020-09-06T16:24:27.005659Z",
     "shell.execute_reply": "2020-09-06T16:24:27.004915Z"
    },
    "papermill": {
     "duration": 0.106005,
     "end_time": "2020-09-06T16:24:27.005802",
     "exception": false,
     "start_time": "2020-09-06T16:24:26.899797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "x = df.drop('label',axis=1)\n",
    "y = df.label\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:27.026636Z",
     "iopub.status.busy": "2020-09-06T16:24:27.025880Z",
     "iopub.status.idle": "2020-09-06T16:24:28.307652Z",
     "shell.execute_reply": "2020-09-06T16:24:28.306564Z"
    },
    "papermill": {
     "duration": 1.293581,
     "end_time": "2020-09-06T16:24:28.307779",
     "exception": false,
     "start_time": "2020-09-06T16:24:27.014198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:28.329941Z",
     "iopub.status.busy": "2020-09-06T16:24:28.329115Z",
     "iopub.status.idle": "2020-09-06T16:24:28.336171Z",
     "shell.execute_reply": "2020-09-06T16:24:28.337417Z"
    },
    "papermill": {
     "duration": 0.021832,
     "end_time": "2020-09-06T16:24:28.337560",
     "exception": false,
     "start_time": "2020-09-06T16:24:28.315728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((42000,28,28,1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:28.376824Z",
     "iopub.status.busy": "2020-09-06T16:24:28.367372Z",
     "iopub.status.idle": "2020-09-06T16:24:28.656298Z",
     "shell.execute_reply": "2020-09-06T16:24:28.656869Z"
    },
    "papermill": {
     "duration": 0.311472,
     "end_time": "2020-09-06T16:24:28.657032",
     "exception": false,
     "start_time": "2020-09-06T16:24:28.345560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array(df2)\n",
    "x1 = scaler.fit_transform(x1)\n",
    "x1 = x1.reshape((28000,28,28,1))\n",
    "x1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:28.679111Z",
     "iopub.status.busy": "2020-09-06T16:24:28.678235Z",
     "iopub.status.idle": "2020-09-06T16:24:28.689977Z",
     "shell.execute_reply": "2020-09-06T16:24:28.689310Z"
    },
    "papermill": {
     "duration": 0.025316,
     "end_time": "2020-09-06T16:24:28.690102",
     "exception": false,
     "start_time": "2020-09-06T16:24:28.664786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y= y.reshape((-1,1))\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.007484,
     "end_time": "2020-09-06T16:24:28.705645",
     "exception": false,
     "start_time": "2020-09-06T16:24:28.698161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test train split from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:28.727549Z",
     "iopub.status.busy": "2020-09-06T16:24:28.726780Z",
     "iopub.status.idle": "2020-09-06T16:24:29.162215Z",
     "shell.execute_reply": "2020-09-06T16:24:29.162895Z"
    },
    "papermill": {
     "duration": 0.449625,
     "end_time": "2020-09-06T16:24:29.163077",
     "exception": false,
     "start_time": "2020-09-06T16:24:28.713452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 28, 28, 1)\n",
      "(33600, 10)\n",
      "(8400, 28, 28, 1)\n",
      "(8400, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "x_train,x_test,y_train,y_test = tts(x,y,test_size = 0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.007602,
     "end_time": "2020-09-06T16:24:29.179081",
     "exception": false,
     "start_time": "2020-09-06T16:24:29.171479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# creating model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:29.201536Z",
     "iopub.status.busy": "2020-09-06T16:24:29.200738Z",
     "iopub.status.idle": "2020-09-06T16:24:34.843139Z",
     "shell.execute_reply": "2020-09-06T16:24:34.841885Z"
    },
    "papermill": {
     "duration": 5.656778,
     "end_time": "2020-09-06T16:24:34.843282",
     "exception": false,
     "start_time": "2020-09-06T16:24:29.186504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing required librery and moduls\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:34.872990Z",
     "iopub.status.busy": "2020-09-06T16:24:34.872194Z",
     "iopub.status.idle": "2020-09-06T16:24:38.239847Z",
     "shell.execute_reply": "2020-09-06T16:24:38.238906Z"
    },
    "papermill": {
     "duration": 3.388177,
     "end_time": "2020-09-06T16:24:38.240048",
     "exception": false,
     "start_time": "2020-09-06T16:24:34.851871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 953,322\n",
      "Trainable params: 953,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:38.271515Z",
     "iopub.status.busy": "2020-09-06T16:24:38.270631Z",
     "iopub.status.idle": "2020-09-06T16:24:38.272902Z",
     "shell.execute_reply": "2020-09-06T16:24:38.272227Z"
    },
    "papermill": {
     "duration": 0.020912,
     "end_time": "2020-09-06T16:24:38.273028",
     "exception": false,
     "start_time": "2020-09-06T16:24:38.252116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting for early stopping\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor='val_loss',\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-5,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=25,\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:24:38.310354Z",
     "iopub.status.busy": "2020-09-06T16:24:38.309484Z",
     "iopub.status.idle": "2020-09-06T16:56:16.945864Z",
     "shell.execute_reply": "2020-09-06T16:56:16.946356Z"
    },
    "papermill": {
     "duration": 1898.663101,
     "end_time": "2020-09-06T16:56:16.946515",
     "exception": false,
     "start_time": "2020-09-06T16:24:38.283414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.3166 - accuracy: 0.8985 - val_loss: 0.0599 - val_accuracy: 0.9823\n",
      "Epoch 2/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0925 - accuracy: 0.9737 - val_loss: 0.0344 - val_accuracy: 0.9888\n",
      "Epoch 3/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0690 - accuracy: 0.9804 - val_loss: 0.0291 - val_accuracy: 0.9901\n",
      "Epoch 4/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0574 - accuracy: 0.9839 - val_loss: 0.0188 - val_accuracy: 0.9940\n",
      "Epoch 5/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0493 - accuracy: 0.9862 - val_loss: 0.0143 - val_accuracy: 0.9960\n",
      "Epoch 6/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0446 - accuracy: 0.9873 - val_loss: 0.0157 - val_accuracy: 0.9955\n",
      "Epoch 7/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0426 - accuracy: 0.9879 - val_loss: 0.0139 - val_accuracy: 0.9963\n",
      "Epoch 8/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0392 - accuracy: 0.9895 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
      "Epoch 9/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 0.0078 - val_accuracy: 0.9975\n",
      "Epoch 10/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "Epoch 11/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 12/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0301 - accuracy: 0.9916 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 13/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0307 - accuracy: 0.9920 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 14/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0266 - accuracy: 0.9928 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 15/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "Epoch 16/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
      "Epoch 17/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 18/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0205 - accuracy: 0.9941 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
      "Epoch 19/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.0027 - val_accuracy: 0.9989\n",
      "Epoch 20/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0209 - accuracy: 0.9941 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 21/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 0.0045 - val_accuracy: 0.9982\n",
      "Epoch 22/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.0013 - val_accuracy: 0.9995\n",
      "Epoch 23/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
      "Epoch 24/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 25/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
      "Epoch 26/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.0017 - val_accuracy: 0.9994\n",
      "Epoch 27/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.0018 - val_accuracy: 0.9992\n",
      "Epoch 28/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 29/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 30/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "Epoch 31/500\n",
      "657/657 [==============================] - 5s 7ms/step - loss: 0.0192 - accuracy: 0.9952 - val_loss: 0.0029 - val_accuracy: 0.9988\n",
      "Epoch 32/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 33/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 9.0400e-04 - val_accuracy: 0.9998\n",
      "Epoch 34/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0175 - accuracy: 0.9956 - val_loss: 0.0022 - val_accuracy: 0.9993\n",
      "Epoch 35/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.0019 - val_accuracy: 0.9989\n",
      "Epoch 36/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0189 - accuracy: 0.9955 - val_loss: 0.0027 - val_accuracy: 0.9989\n",
      "Epoch 37/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
      "Epoch 38/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
      "Epoch 39/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
      "Epoch 40/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 41/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 6.9231e-04 - val_accuracy: 0.9998\n",
      "Epoch 42/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
      "Epoch 43/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "Epoch 44/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "Epoch 45/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0177 - accuracy: 0.9955 - val_loss: 5.7311e-04 - val_accuracy: 0.9999\n",
      "Epoch 46/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 7.3406e-04 - val_accuracy: 0.9998\n",
      "Epoch 47/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0178 - accuracy: 0.9959 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 48/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 49/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 7.4400e-04 - val_accuracy: 0.9999\n",
      "Epoch 50/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 51/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0197 - accuracy: 0.9952 - val_loss: 9.5517e-04 - val_accuracy: 0.9996\n",
      "Epoch 52/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0178 - accuracy: 0.9955 - val_loss: 4.1452e-04 - val_accuracy: 0.9999\n",
      "Epoch 53/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 7.4144e-04 - val_accuracy: 0.9999\n",
      "Epoch 54/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 8.6641e-04 - val_accuracy: 0.9995\n",
      "Epoch 55/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 6.6492e-04 - val_accuracy: 0.9998\n",
      "Epoch 56/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 57/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 8.8723e-04 - val_accuracy: 0.9996\n",
      "Epoch 58/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
      "Epoch 59/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 60/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 8.9782e-04 - val_accuracy: 0.9998\n",
      "Epoch 61/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
      "Epoch 62/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0189 - accuracy: 0.9960 - val_loss: 5.3511e-04 - val_accuracy: 0.9999\n",
      "Epoch 63/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 4.7995e-04 - val_accuracy: 0.9999\n",
      "Epoch 64/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 2.9208e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 66/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 4.0181e-04 - val_accuracy: 0.9999\n",
      "Epoch 67/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 3.8329e-04 - val_accuracy: 0.9999\n",
      "Epoch 68/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 3.6795e-04 - val_accuracy: 0.9999\n",
      "Epoch 69/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 7.3722e-04 - val_accuracy: 0.9999\n",
      "Epoch 70/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
      "Epoch 71/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 3.5222e-04 - val_accuracy: 0.9999\n",
      "Epoch 72/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 73/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0176 - accuracy: 0.9961 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
      "Epoch 74/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 9.5855e-04 - val_accuracy: 0.9999\n",
      "Epoch 75/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 9.3293e-04 - val_accuracy: 0.9999\n",
      "Epoch 76/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0159 - accuracy: 0.9961 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 77/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
      "Epoch 78/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 3.7625e-04 - val_accuracy: 0.9998\n",
      "Epoch 79/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 80/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0177 - accuracy: 0.9961 - val_loss: 5.0352e-04 - val_accuracy: 0.9999\n",
      "Epoch 81/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 1.9795e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "Epoch 83/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 4.3756e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 1.3170e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 7.7854e-04 - val_accuracy: 0.9998\n",
      "Epoch 86/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 4.9771e-04 - val_accuracy: 0.9999\n",
      "Epoch 87/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 6.7642e-04 - val_accuracy: 0.9998\n",
      "Epoch 88/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0180 - accuracy: 0.9960 - val_loss: 4.9679e-04 - val_accuracy: 0.9999\n",
      "Epoch 89/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 2.8753e-04 - val_accuracy: 0.9999\n",
      "Epoch 90/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0181 - accuracy: 0.9966 - val_loss: 6.0421e-04 - val_accuracy: 0.9998\n",
      "Epoch 91/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 0.0038 - val_accuracy: 0.9989\n",
      "Epoch 92/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
      "Epoch 93/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 2.1651e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 3.4913e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 1.8048e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 3.1030e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 4.3473e-04 - val_accuracy: 0.9999\n",
      "Epoch 98/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 2.5271e-04 - val_accuracy: 0.9999\n",
      "Epoch 99/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0175 - accuracy: 0.9964 - val_loss: 9.3875e-04 - val_accuracy: 0.9999\n",
      "Epoch 100/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 7.7344e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 3.2422e-04 - val_accuracy: 0.9999\n",
      "Epoch 102/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 1.3019e-04 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 6.1935e-04 - val_accuracy: 0.9998\n",
      "Epoch 104/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0177 - accuracy: 0.9965 - val_loss: 3.4801e-04 - val_accuracy: 0.9999\n",
      "Epoch 105/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0177 - accuracy: 0.9965 - val_loss: 3.8394e-04 - val_accuracy: 0.9999\n",
      "Epoch 106/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 4.3459e-04 - val_accuracy: 0.9999\n",
      "Epoch 107/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 8.7501e-04 - val_accuracy: 0.9995\n",
      "Epoch 108/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0185 - accuracy: 0.9965 - val_loss: 0.0010 - val_accuracy: 0.9995\n",
      "Epoch 109/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "Epoch 110/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 2.0890e-04 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 112/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0202 - accuracy: 0.9960 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 113/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 3.0739e-04 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 5.3122e-04 - val_accuracy: 0.9999\n",
      "Epoch 115/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 2.4718e-04 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0180 - accuracy: 0.9962 - val_loss: 5.0360e-04 - val_accuracy: 0.9999\n",
      "Epoch 117/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 3.2833e-04 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.0010 - val_accuracy: 0.9995\n",
      "Epoch 119/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0167 - accuracy: 0.9967 - val_loss: 5.8793e-05 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 1.1959e-04 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 3.5320e-04 - val_accuracy: 0.9998\n",
      "Epoch 122/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 3.2283e-04 - val_accuracy: 0.9998\n",
      "Epoch 123/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0164 - accuracy: 0.9967 - val_loss: 6.8648e-04 - val_accuracy: 0.9998\n",
      "Epoch 124/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 3.0250e-04 - val_accuracy: 0.9998\n",
      "Epoch 125/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 5.8619e-04 - val_accuracy: 0.9998\n",
      "Epoch 126/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 5.2722e-04 - val_accuracy: 0.9998\n",
      "Epoch 127/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 2.2401e-04 - val_accuracy: 0.9999\n",
      "Epoch 128/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0177 - accuracy: 0.9964 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 129/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0210 - accuracy: 0.9958 - val_loss: 2.6811e-04 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0213 - accuracy: 0.9962 - val_loss: 3.2220e-04 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 4.3291e-04 - val_accuracy: 0.9999\n",
      "Epoch 132/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 7.1925e-05 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 2.8505e-04 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 1.1699e-04 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 2.3341e-04 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0177 - accuracy: 0.9966 - val_loss: 4.1484e-04 - val_accuracy: 0.9998\n",
      "Epoch 137/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 2.1651e-04 - val_accuracy: 0.9999\n",
      "Epoch 138/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 3.7256e-04 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0180 - accuracy: 0.9967 - val_loss: 2.8165e-04 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 1.6392e-04 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
      "Epoch 142/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0235 - accuracy: 0.9959 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "Epoch 143/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 3.9380e-04 - val_accuracy: 0.9999\n",
      "Epoch 144/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 6.4581e-04 - val_accuracy: 0.9998\n",
      "Epoch 145/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 1.0687e-04 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0174 - accuracy: 0.9965 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 147/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 2.1831e-04 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 2.8051e-04 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0170 - accuracy: 0.9966 - val_loss: 2.5289e-04 - val_accuracy: 0.9999\n",
      "Epoch 150/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 2.0145e-04 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0217 - accuracy: 0.9962 - val_loss: 1.9377e-04 - val_accuracy: 0.9999\n",
      "Epoch 152/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0248 - accuracy: 0.9956 - val_loss: 4.1013e-04 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 3.0772e-04 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0189 - accuracy: 0.9960 - val_loss: 7.0329e-04 - val_accuracy: 0.9999\n",
      "Epoch 155/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 1.3427e-04 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 4.9426e-05 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 3.7844e-05 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 2.2600e-04 - val_accuracy: 0.9999\n",
      "Epoch 159/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 2.2444e-04 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0160 - accuracy: 0.9968 - val_loss: 6.6649e-04 - val_accuracy: 0.9999\n",
      "Epoch 161/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0189 - accuracy: 0.9966 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "Epoch 162/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 1.9720e-04 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0175 - accuracy: 0.9965 - val_loss: 8.2317e-04 - val_accuracy: 0.9999\n",
      "Epoch 164/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 165/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "Epoch 166/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 7.5514e-04 - val_accuracy: 0.9998\n",
      "Epoch 167/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0204 - accuracy: 0.9963 - val_loss: 0.0036 - val_accuracy: 0.9996\n",
      "Epoch 168/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0236 - accuracy: 0.9956 - val_loss: 4.0333e-04 - val_accuracy: 0.9999\n",
      "Epoch 169/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0182 - accuracy: 0.9964 - val_loss: 3.6228e-04 - val_accuracy: 0.9999\n",
      "Epoch 170/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 2.5005e-04 - val_accuracy: 0.9999\n",
      "Epoch 171/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 3.2109e-04 - val_accuracy: 0.9999\n",
      "Epoch 172/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 3.1605e-04 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0210 - accuracy: 0.9961 - val_loss: 2.1873e-04 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 3.5892e-04 - val_accuracy: 0.9999\n",
      "Epoch 175/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 3.8286e-04 - val_accuracy: 0.9999\n",
      "Epoch 176/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 3.7619e-04 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 2.5451e-04 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 1.3354e-04 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 3.0919e-05 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0149 - accuracy: 0.9967 - val_loss: 2.3007e-04 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 7.6346e-04 - val_accuracy: 0.9998\n",
      "Epoch 182/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 2.3756e-04 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0170 - accuracy: 0.9970 - val_loss: 4.4294e-04 - val_accuracy: 0.9999\n",
      "Epoch 184/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 1.5226e-04 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0207 - accuracy: 0.9964 - val_loss: 1.0561e-04 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0209 - accuracy: 0.9966 - val_loss: 5.0062e-04 - val_accuracy: 0.9999\n",
      "Epoch 187/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0190 - accuracy: 0.9968 - val_loss: 2.9627e-04 - val_accuracy: 0.9999\n",
      "Epoch 188/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0164 - accuracy: 0.9970 - val_loss: 7.3984e-04 - val_accuracy: 0.9996\n",
      "Epoch 189/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0166 - accuracy: 0.9968 - val_loss: 2.4529e-04 - val_accuracy: 0.9999\n",
      "Epoch 190/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0177 - accuracy: 0.9967 - val_loss: 2.2968e-04 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0158 - accuracy: 0.9972 - val_loss: 2.9009e-04 - val_accuracy: 0.9999\n",
      "Epoch 192/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 1.3459e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0206 - accuracy: 0.9966 - val_loss: 4.1653e-04 - val_accuracy: 0.9999\n",
      "Epoch 194/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 3.0888e-04 - val_accuracy: 0.9999\n",
      "Epoch 195/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0209 - accuracy: 0.9963 - val_loss: 3.9208e-04 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0196 - accuracy: 0.9961 - val_loss: 3.2178e-04 - val_accuracy: 0.9999\n",
      "Epoch 197/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 1.1217e-04 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0179 - accuracy: 0.9971 - val_loss: 8.9527e-04 - val_accuracy: 0.9998\n",
      "Epoch 199/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
      "Epoch 200/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0237 - accuracy: 0.9961 - val_loss: 5.3109e-05 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0254 - accuracy: 0.9958 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 202/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0159 - accuracy: 0.9968 - val_loss: 7.8430e-05 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0190 - accuracy: 0.9968 - val_loss: 9.6284e-05 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 1.7969e-04 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0257 - accuracy: 0.9955 - val_loss: 8.1616e-04 - val_accuracy: 0.9998\n",
      "Epoch 206/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0201 - accuracy: 0.9965 - val_loss: 3.9961e-04 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0169 - accuracy: 0.9968 - val_loss: 7.4631e-04 - val_accuracy: 0.9999\n",
      "Epoch 208/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 2.0463e-04 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0186 - accuracy: 0.9965 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 210/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0178 - accuracy: 0.9966 - val_loss: 2.1651e-04 - val_accuracy: 0.9999\n",
      "Epoch 211/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 8.6921e-04 - val_accuracy: 0.9999\n",
      "Epoch 212/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0190 - accuracy: 0.9966 - val_loss: 1.9010e-04 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 1.7100e-04 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0236 - accuracy: 0.9968 - val_loss: 4.4971e-04 - val_accuracy: 0.9999\n",
      "Epoch 215/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 3.3198e-04 - val_accuracy: 0.9999\n",
      "Epoch 216/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 8.4878e-04 - val_accuracy: 0.9998\n",
      "Epoch 217/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 4.8668e-04 - val_accuracy: 0.9999\n",
      "Epoch 218/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0192 - accuracy: 0.9962 - val_loss: 3.8674e-04 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0196 - accuracy: 0.9961 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
      "Epoch 220/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0221 - accuracy: 0.9958 - val_loss: 3.5366e-04 - val_accuracy: 0.9999\n",
      "Epoch 221/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0165 - accuracy: 0.9972 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
      "Epoch 222/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0200 - accuracy: 0.9967 - val_loss: 3.9414e-04 - val_accuracy: 0.9999\n",
      "Epoch 223/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0198 - accuracy: 0.9967 - val_loss: 8.8090e-04 - val_accuracy: 0.9996\n",
      "Epoch 224/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 2.3301e-04 - val_accuracy: 0.9999\n",
      "Epoch 225/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0215 - accuracy: 0.9969 - val_loss: 4.3983e-04 - val_accuracy: 0.9998\n",
      "Epoch 226/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0155 - accuracy: 0.9975 - val_loss: 1.2484e-04 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 2.7897e-04 - val_accuracy: 0.9999\n",
      "Epoch 228/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0186 - accuracy: 0.9965 - val_loss: 3.7077e-04 - val_accuracy: 0.9999\n",
      "Epoch 229/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 5.9258e-04 - val_accuracy: 0.9999\n",
      "Epoch 230/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0190 - accuracy: 0.9963 - val_loss: 6.3318e-04 - val_accuracy: 0.9996\n",
      "Epoch 231/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0282 - accuracy: 0.9955 - val_loss: 5.2883e-04 - val_accuracy: 0.9998\n",
      "Epoch 232/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 2.8718e-04 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 2.3734e-04 - val_accuracy: 0.9999\n",
      "Epoch 234/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 2.2736e-05 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 2.2577e-04 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0156 - accuracy: 0.9974 - val_loss: 2.1161e-04 - val_accuracy: 0.9999\n",
      "Epoch 237/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 5.2552e-04 - val_accuracy: 0.9999\n",
      "Epoch 238/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0190 - accuracy: 0.9969 - val_loss: 1.3887e-04 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0201 - accuracy: 0.9971 - val_loss: 1.5199e-04 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0168 - accuracy: 0.9970 - val_loss: 1.7417e-04 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0167 - accuracy: 0.9972 - val_loss: 2.1155e-04 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0194 - accuracy: 0.9967 - val_loss: 3.0290e-04 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 5.2215e-04 - val_accuracy: 0.9998\n",
      "Epoch 244/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0183 - accuracy: 0.9965 - val_loss: 2.1602e-04 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0199 - accuracy: 0.9969 - val_loss: 6.1715e-04 - val_accuracy: 0.9998\n",
      "Epoch 246/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0238 - accuracy: 0.9959 - val_loss: 1.1978e-04 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 1.2761e-04 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0185 - accuracy: 0.9966 - val_loss: 2.8840e-05 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0192 - accuracy: 0.9968 - val_loss: 3.0226e-04 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0221 - accuracy: 0.9968 - val_loss: 6.0090e-04 - val_accuracy: 0.9995\n",
      "Epoch 251/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0197 - accuracy: 0.9965 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
      "Epoch 252/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0211 - accuracy: 0.9961 - val_loss: 6.3776e-04 - val_accuracy: 0.9998\n",
      "Epoch 253/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0173 - accuracy: 0.9971 - val_loss: 6.7634e-05 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0204 - accuracy: 0.9971 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 255/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0212 - accuracy: 0.9968 - val_loss: 5.8448e-05 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 2.3362e-05 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0240 - accuracy: 0.9964 - val_loss: 9.0794e-05 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 2.2834e-04 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0208 - accuracy: 0.9966 - val_loss: 3.2981e-04 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0184 - accuracy: 0.9970 - val_loss: 8.7311e-04 - val_accuracy: 0.9996\n",
      "Epoch 261/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0172 - accuracy: 0.9970 - val_loss: 3.9892e-04 - val_accuracy: 0.9998\n",
      "Epoch 262/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0171 - accuracy: 0.9971 - val_loss: 1.9622e-04 - val_accuracy: 0.9999\n",
      "Epoch 263/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0160 - accuracy: 0.9973 - val_loss: 3.5182e-04 - val_accuracy: 0.9999\n",
      "Epoch 264/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0175 - accuracy: 0.9970 - val_loss: 2.5110e-04 - val_accuracy: 0.9999\n",
      "Epoch 265/500\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 0.0168 - accuracy: 0.9971 - val_loss: 2.5876e-04 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "657/657 [==============================] - 5s 7ms/step - loss: 0.0208 - accuracy: 0.9967 - val_loss: 1.7350e-04 - val_accuracy: 0.9999\n",
      "Epoch 267/500\n",
      "657/657 [==============================] - 5s 7ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 1.8390e-04 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "657/657 [==============================] - 5s 7ms/step - loss: 0.0190 - accuracy: 0.9965 - val_loss: 8.6761e-04 - val_accuracy: 0.9996\n",
      "Epoch 269/500\n",
      "657/657 [==============================] - 7s 10ms/step - loss: 0.0196 - accuracy: 0.9970 - val_loss: 2.5465e-04 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "657/657 [==============================] - 6s 9ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 1.0908e-04 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0214 - accuracy: 0.9967 - val_loss: 4.9605e-04 - val_accuracy: 0.9998\n",
      "Epoch 272/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0199 - accuracy: 0.9965 - val_loss: 5.3922e-04 - val_accuracy: 0.9999\n",
      "Epoch 273/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 4.9929e-04 - val_accuracy: 0.9999\n",
      "Epoch 274/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0189 - accuracy: 0.9974 - val_loss: 1.5421e-04 - val_accuracy: 0.9999\n",
      "Epoch 275/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0159 - accuracy: 0.9974 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 276/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0183 - accuracy: 0.9972 - val_loss: 2.0207e-04 - val_accuracy: 0.9999\n",
      "Epoch 277/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 8.8667e-05 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0159 - accuracy: 0.9976 - val_loss: 2.8941e-05 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 2.0168e-04 - val_accuracy: 0.9999\n",
      "Epoch 280/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0197 - accuracy: 0.9971 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "Epoch 281/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0172 - accuracy: 0.9973 - val_loss: 6.1049e-04 - val_accuracy: 0.9998\n",
      "Epoch 282/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0139 - accuracy: 0.9977 - val_loss: 6.2591e-05 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 6.6947e-05 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0263 - accuracy: 0.9964 - val_loss: 8.8727e-05 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0181 - accuracy: 0.9971 - val_loss: 5.8098e-05 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 4.9820e-04 - val_accuracy: 0.9999\n",
      "Epoch 287/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0181 - accuracy: 0.9971 - val_loss: 2.9747e-04 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 3.2461e-04 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 5.8041e-04 - val_accuracy: 0.9999\n",
      "Epoch 290/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0282 - accuracy: 0.9955 - val_loss: 0.0010 - val_accuracy: 0.9995\n",
      "Epoch 291/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0233 - accuracy: 0.9963 - val_loss: 3.5674e-04 - val_accuracy: 0.9999\n",
      "Epoch 292/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0184 - accuracy: 0.9973 - val_loss: 3.2851e-04 - val_accuracy: 0.9999\n",
      "Epoch 293/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0163 - accuracy: 0.9976 - val_loss: 1.9942e-04 - val_accuracy: 0.9999\n",
      "Epoch 294/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0204 - accuracy: 0.9970 - val_loss: 1.4808e-04 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 2.8413e-04 - val_accuracy: 0.9999\n",
      "Epoch 296/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0164 - accuracy: 0.9974 - val_loss: 3.8895e-04 - val_accuracy: 0.9999\n",
      "Epoch 297/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 1.0419e-04 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0187 - accuracy: 0.9971 - val_loss: 1.4737e-04 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0214 - accuracy: 0.9968 - val_loss: 1.9234e-04 - val_accuracy: 0.9999\n",
      "Epoch 300/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0204 - accuracy: 0.9969 - val_loss: 2.7887e-04 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0205 - accuracy: 0.9965 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "Epoch 302/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 1.9427e-04 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 3.2331e-04 - val_accuracy: 0.9998\n",
      "Epoch 304/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0162 - accuracy: 0.9977 - val_loss: 1.8643e-04 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0254 - accuracy: 0.9959 - val_loss: 1.3861e-04 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0133 - accuracy: 0.9973 - val_loss: 4.2361e-04 - val_accuracy: 0.9999\n",
      "Epoch 307/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0181 - accuracy: 0.9970 - val_loss: 3.1615e-04 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 1.4811e-04 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0199 - accuracy: 0.9970 - val_loss: 7.0365e-04 - val_accuracy: 0.9996\n",
      "Epoch 310/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0220 - accuracy: 0.9964 - val_loss: 4.0946e-04 - val_accuracy: 0.9999\n",
      "Epoch 311/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 4.0918e-04 - val_accuracy: 0.9999\n",
      "Epoch 312/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0165 - accuracy: 0.9976 - val_loss: 7.3006e-04 - val_accuracy: 0.9998\n",
      "Epoch 313/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0238 - accuracy: 0.9966 - val_loss: 6.9178e-04 - val_accuracy: 0.9999\n",
      "Epoch 314/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0179 - accuracy: 0.9968 - val_loss: 2.2875e-04 - val_accuracy: 0.9999\n",
      "Epoch 315/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0289 - accuracy: 0.9965 - val_loss: 2.5079e-04 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 9.7651e-05 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 1.6756e-04 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0188 - accuracy: 0.9970 - val_loss: 2.1913e-04 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0256 - accuracy: 0.9956 - val_loss: 5.9743e-05 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0235 - accuracy: 0.9963 - val_loss: 3.8973e-04 - val_accuracy: 0.9999\n",
      "Epoch 321/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 2.5799e-04 - val_accuracy: 0.9999\n",
      "Epoch 322/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0158 - accuracy: 0.9975 - val_loss: 2.5114e-04 - val_accuracy: 0.9999\n",
      "Epoch 323/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0194 - accuracy: 0.9973 - val_loss: 2.5107e-04 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0230 - accuracy: 0.9965 - val_loss: 1.1677e-04 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0235 - accuracy: 0.9964 - val_loss: 9.2166e-04 - val_accuracy: 0.9999\n",
      "Epoch 326/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0206 - accuracy: 0.9968 - val_loss: 8.4146e-05 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0250 - accuracy: 0.9968 - val_loss: 1.0674e-04 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0199 - accuracy: 0.9968 - val_loss: 1.3484e-04 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0199 - accuracy: 0.9967 - val_loss: 5.4876e-04 - val_accuracy: 0.9998\n",
      "Epoch 330/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0220 - accuracy: 0.9967 - val_loss: 1.9868e-04 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0195 - accuracy: 0.9974 - val_loss: 6.3102e-04 - val_accuracy: 0.9999\n",
      "Epoch 332/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0237 - accuracy: 0.9965 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "Epoch 333/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0185 - accuracy: 0.9970 - val_loss: 5.1272e-04 - val_accuracy: 0.9999\n",
      "Epoch 334/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0196 - accuracy: 0.9968 - val_loss: 2.0694e-04 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 2.5693e-04 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0196 - accuracy: 0.9970 - val_loss: 3.3677e-04 - val_accuracy: 0.9999\n",
      "Epoch 337/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0234 - accuracy: 0.9967 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 338/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0214 - accuracy: 0.9964 - val_loss: 8.0338e-04 - val_accuracy: 0.9999\n",
      "Epoch 339/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0205 - accuracy: 0.9962 - val_loss: 5.3900e-04 - val_accuracy: 0.9998\n",
      "Epoch 340/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0256 - accuracy: 0.9970 - val_loss: 1.7547e-05 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0268 - accuracy: 0.9965 - val_loss: 2.0832e-04 - val_accuracy: 0.9999\n",
      "Epoch 342/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0203 - accuracy: 0.9970 - val_loss: 2.5222e-04 - val_accuracy: 0.9999\n",
      "Epoch 343/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0240 - accuracy: 0.9968 - val_loss: 1.0449e-04 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0158 - accuracy: 0.9972 - val_loss: 2.1597e-04 - val_accuracy: 0.9999\n",
      "Epoch 345/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0179 - accuracy: 0.9974 - val_loss: 6.3369e-04 - val_accuracy: 0.9998\n",
      "Epoch 346/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0161 - accuracy: 0.9972 - val_loss: 3.3345e-04 - val_accuracy: 0.9999\n",
      "Epoch 347/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0181 - accuracy: 0.9970 - val_loss: 0.0010 - val_accuracy: 0.9999\n",
      "Epoch 348/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0275 - accuracy: 0.9962 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "Epoch 349/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0176 - accuracy: 0.9967 - val_loss: 5.9706e-04 - val_accuracy: 0.9998\n",
      "Epoch 350/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0178 - accuracy: 0.9970 - val_loss: 3.2883e-04 - val_accuracy: 0.9999\n",
      "Epoch 351/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0226 - accuracy: 0.9967 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 352/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0232 - accuracy: 0.9957 - val_loss: 8.3936e-05 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 9.7337e-05 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0177 - accuracy: 0.9971 - val_loss: 2.3717e-04 - val_accuracy: 0.9999\n",
      "Epoch 355/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0218 - accuracy: 0.9972 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 356/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 8.7524e-05 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0212 - accuracy: 0.9973 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 358/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0172 - accuracy: 0.9972 - val_loss: 7.5831e-05 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0154 - accuracy: 0.9974 - val_loss: 3.4893e-05 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0247 - accuracy: 0.9966 - val_loss: 8.5511e-04 - val_accuracy: 0.9999\n",
      "Epoch 361/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0266 - accuracy: 0.9964 - val_loss: 2.1548e-04 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0227 - accuracy: 0.9973 - val_loss: 2.1828e-04 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0188 - accuracy: 0.9973 - val_loss: 1.1006e-04 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "657/657 [==============================] - 5s 7ms/step - loss: 0.0285 - accuracy: 0.9960 - val_loss: 2.2465e-04 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0210 - accuracy: 0.9967 - val_loss: 1.9554e-05 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 4.5269e-06 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0216 - accuracy: 0.9972 - val_loss: 3.2149e-04 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0199 - accuracy: 0.9969 - val_loss: 1.3955e-04 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0204 - accuracy: 0.9971 - val_loss: 1.1197e-04 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0191 - accuracy: 0.9966 - val_loss: 1.3100e-04 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0176 - accuracy: 0.9973 - val_loss: 4.4761e-04 - val_accuracy: 0.9999\n",
      "Epoch 372/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0191 - accuracy: 0.9972 - val_loss: 1.0156e-04 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0224 - accuracy: 0.9972 - val_loss: 1.5576e-04 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0219 - accuracy: 0.9972 - val_loss: 1.6094e-04 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0202 - accuracy: 0.9970 - val_loss: 3.1337e-05 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0231 - accuracy: 0.9969 - val_loss: 3.5521e-04 - val_accuracy: 0.9999\n",
      "Epoch 377/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0229 - accuracy: 0.9965 - val_loss: 4.8860e-05 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0243 - accuracy: 0.9967 - val_loss: 1.6656e-04 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0200 - accuracy: 0.9970 - val_loss: 4.7921e-04 - val_accuracy: 0.9999\n",
      "Epoch 380/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0216 - accuracy: 0.9964 - val_loss: 1.4558e-04 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0207 - accuracy: 0.9967 - val_loss: 2.0383e-04 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0174 - accuracy: 0.9971 - val_loss: 1.3645e-04 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0170 - accuracy: 0.9972 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
      "Epoch 384/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0208 - accuracy: 0.9967 - val_loss: 1.3838e-04 - val_accuracy: 0.9999\n",
      "Epoch 385/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0293 - accuracy: 0.9964 - val_loss: 7.0044e-04 - val_accuracy: 0.9998\n",
      "Epoch 386/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0198 - accuracy: 0.9970 - val_loss: 0.0011 - val_accuracy: 0.9994\n",
      "Epoch 387/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 1.8617e-04 - val_accuracy: 0.9999\n",
      "Epoch 388/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0324 - accuracy: 0.9955 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
      "Epoch 389/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 8.7960e-04 - val_accuracy: 0.9996\n",
      "Epoch 390/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0226 - accuracy: 0.9967 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "Epoch 391/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0189 - accuracy: 0.9972 - val_loss: 9.4361e-04 - val_accuracy: 0.9998\n",
      "Epoch 392/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0268 - accuracy: 0.9961 - val_loss: 3.6936e-04 - val_accuracy: 0.9998\n",
      "Epoch 393/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0317 - accuracy: 0.9963 - val_loss: 6.1269e-04 - val_accuracy: 0.9996\n",
      "Epoch 394/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0201 - accuracy: 0.9972 - val_loss: 5.4603e-04 - val_accuracy: 0.9998\n",
      "Epoch 395/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0151 - accuracy: 0.9978 - val_loss: 0.0014 - val_accuracy: 0.9994\n",
      "Epoch 396/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0202 - accuracy: 0.9970 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "Epoch 397/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0213 - accuracy: 0.9966 - val_loss: 2.5617e-04 - val_accuracy: 0.9999\n",
      "Epoch 398/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0187 - accuracy: 0.9972 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
      "Epoch 399/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0171 - accuracy: 0.9972 - val_loss: 5.8239e-05 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0300 - accuracy: 0.9968 - val_loss: 3.1338e-04 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 2.6537e-04 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0215 - accuracy: 0.9974 - val_loss: 8.5002e-05 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0263 - accuracy: 0.9964 - val_loss: 0.0013 - val_accuracy: 0.9995\n",
      "Epoch 404/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0145 - accuracy: 0.9978 - val_loss: 2.2625e-06 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0200 - accuracy: 0.9969 - val_loss: 8.9951e-04 - val_accuracy: 0.9996\n",
      "Epoch 406/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0290 - accuracy: 0.9959 - val_loss: 2.3828e-04 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0234 - accuracy: 0.9964 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 408/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0307 - accuracy: 0.9961 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
      "Epoch 409/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0237 - accuracy: 0.9972 - val_loss: 7.5843e-04 - val_accuracy: 0.9996\n",
      "Epoch 410/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0209 - accuracy: 0.9970 - val_loss: 1.6272e-04 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0181 - accuracy: 0.9975 - val_loss: 1.7067e-05 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0225 - accuracy: 0.9971 - val_loss: 8.0082e-04 - val_accuracy: 0.9998\n",
      "Epoch 413/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0230 - accuracy: 0.9968 - val_loss: 3.5899e-04 - val_accuracy: 0.9999\n",
      "Epoch 414/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0201 - accuracy: 0.9972 - val_loss: 4.1467e-04 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 1.9160e-04 - val_accuracy: 0.9999\n",
      "Epoch 416/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0183 - accuracy: 0.9975 - val_loss: 1.4056e-04 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0238 - accuracy: 0.9961 - val_loss: 0.0010 - val_accuracy: 0.9995\n",
      "Epoch 418/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0235 - accuracy: 0.9968 - val_loss: 9.4532e-04 - val_accuracy: 0.9998\n",
      "Epoch 419/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0199 - accuracy: 0.9973 - val_loss: 4.8781e-04 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0225 - accuracy: 0.9966 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
      "Epoch 421/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0221 - accuracy: 0.9968 - val_loss: 1.3268e-04 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 3.6110e-04 - val_accuracy: 0.9999\n",
      "Epoch 423/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0232 - accuracy: 0.9965 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "Epoch 424/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0241 - accuracy: 0.9966 - val_loss: 3.5999e-04 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0247 - accuracy: 0.9970 - val_loss: 1.0576e-04 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 5.0626e-04 - val_accuracy: 0.9999\n",
      "Epoch 427/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0172 - accuracy: 0.9975 - val_loss: 1.0801e-04 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0210 - accuracy: 0.9968 - val_loss: 2.7285e-04 - val_accuracy: 0.9999\n",
      "Epoch 429/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0252 - accuracy: 0.9968 - val_loss: 4.1952e-04 - val_accuracy: 0.9999\n",
      "Epoch 430/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0190 - accuracy: 0.9973 - val_loss: 1.6403e-05 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0172 - accuracy: 0.9972 - val_loss: 9.5460e-05 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0196 - accuracy: 0.9970 - val_loss: 1.2385e-04 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0233 - accuracy: 0.9967 - val_loss: 5.3041e-04 - val_accuracy: 0.9996\n",
      "Epoch 434/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0202 - accuracy: 0.9966 - val_loss: 2.7376e-04 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0273 - accuracy: 0.9960 - val_loss: 4.6308e-04 - val_accuracy: 0.9999\n",
      "Epoch 436/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0215 - accuracy: 0.9968 - val_loss: 8.8971e-04 - val_accuracy: 0.9996\n",
      "Epoch 437/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0267 - accuracy: 0.9964 - val_loss: 2.4505e-04 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0225 - accuracy: 0.9965 - val_loss: 4.7132e-05 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0208 - accuracy: 0.9970 - val_loss: 9.5897e-05 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0271 - accuracy: 0.9961 - val_loss: 7.6466e-05 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0235 - accuracy: 0.9968 - val_loss: 3.1029e-04 - val_accuracy: 0.9999\n",
      "Epoch 442/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0202 - accuracy: 0.9967 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
      "Epoch 443/500\n",
      "657/657 [==============================] - 4s 7ms/step - loss: 0.0279 - accuracy: 0.9963 - val_loss: 2.2122e-04 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 3.4787e-04 - val_accuracy: 0.9998\n",
      "Epoch 445/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0303 - accuracy: 0.9966 - val_loss: 6.2199e-04 - val_accuracy: 0.9998\n",
      "Epoch 446/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0214 - accuracy: 0.9970 - val_loss: 2.9212e-04 - val_accuracy: 0.9998\n",
      "Epoch 447/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0221 - accuracy: 0.9969 - val_loss: 2.3130e-04 - val_accuracy: 0.9999\n",
      "Epoch 448/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0264 - accuracy: 0.9965 - val_loss: 3.2741e-04 - val_accuracy: 0.9999\n",
      "Epoch 449/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0202 - accuracy: 0.9966 - val_loss: 1.2284e-04 - val_accuracy: 0.9999\n",
      "Epoch 450/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 6.5318e-04 - val_accuracy: 0.9998\n",
      "Epoch 451/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0166 - accuracy: 0.9972 - val_loss: 0.0042 - val_accuracy: 0.9981\n",
      "Epoch 452/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0208 - accuracy: 0.9965 - val_loss: 4.6415e-04 - val_accuracy: 0.9999\n",
      "Epoch 453/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0187 - accuracy: 0.9970 - val_loss: 6.6931e-04 - val_accuracy: 0.9999\n",
      "Epoch 454/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0334 - accuracy: 0.9956 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "Epoch 455/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0265 - accuracy: 0.9964 - val_loss: 8.6235e-04 - val_accuracy: 0.9998\n",
      "Epoch 456/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0292 - accuracy: 0.9962 - val_loss: 1.4945e-04 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0208 - accuracy: 0.9964 - val_loss: 1.2310e-04 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0268 - accuracy: 0.9963 - val_loss: 3.9866e-04 - val_accuracy: 0.9999\n",
      "Epoch 459/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0231 - accuracy: 0.9969 - val_loss: 6.4107e-04 - val_accuracy: 0.9996\n",
      "Epoch 460/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 1.0058e-04 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0243 - accuracy: 0.9965 - val_loss: 1.2374e-04 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0267 - accuracy: 0.9964 - val_loss: 7.1251e-05 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0154 - accuracy: 0.9974 - val_loss: 9.4362e-04 - val_accuracy: 0.9998\n",
      "Epoch 464/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0315 - accuracy: 0.9960 - val_loss: 2.8171e-04 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0170 - accuracy: 0.9971 - val_loss: 3.3241e-04 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0231 - accuracy: 0.9964 - val_loss: 3.2533e-04 - val_accuracy: 0.9999\n",
      "Epoch 467/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0332 - accuracy: 0.9957 - val_loss: 4.4097e-04 - val_accuracy: 0.9999\n",
      "Epoch 468/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0231 - accuracy: 0.9965 - val_loss: 1.2255e-04 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0206 - accuracy: 0.9967 - val_loss: 5.3215e-05 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0298 - accuracy: 0.9968 - val_loss: 4.3014e-05 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0170 - accuracy: 0.9972 - val_loss: 5.5516e-05 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0216 - accuracy: 0.9969 - val_loss: 4.4446e-04 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0226 - accuracy: 0.9967 - val_loss: 6.3416e-04 - val_accuracy: 0.9998\n",
      "Epoch 474/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0260 - accuracy: 0.9961 - val_loss: 6.5766e-05 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0184 - accuracy: 0.9972 - val_loss: 3.5572e-04 - val_accuracy: 0.9999\n",
      "Epoch 476/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0199 - accuracy: 0.9975 - val_loss: 4.5972e-06 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0244 - accuracy: 0.9971 - val_loss: 2.9033e-05 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0260 - accuracy: 0.9964 - val_loss: 2.6500e-04 - val_accuracy: 0.9999\n",
      "Epoch 479/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 2.5390e-05 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0207 - accuracy: 0.9970 - val_loss: 5.4021e-05 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0212 - accuracy: 0.9968 - val_loss: 5.2482e-04 - val_accuracy: 0.9996\n",
      "Epoch 482/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0247 - accuracy: 0.9961 - val_loss: 9.8391e-04 - val_accuracy: 0.9999\n",
      "Epoch 483/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0222 - accuracy: 0.9965 - val_loss: 7.0423e-05 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0181 - accuracy: 0.9970 - val_loss: 2.4256e-04 - val_accuracy: 0.9999\n",
      "Epoch 485/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0203 - accuracy: 0.9971 - val_loss: 2.6933e-05 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0233 - accuracy: 0.9964 - val_loss: 3.8888e-04 - val_accuracy: 0.9999\n",
      "Epoch 487/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0267 - accuracy: 0.9961 - val_loss: 2.0834e-04 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0213 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 489/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0217 - accuracy: 0.9970 - val_loss: 8.0066e-05 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 7.1200e-04 - val_accuracy: 0.9998\n",
      "Epoch 491/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0341 - accuracy: 0.9953 - val_loss: 8.1136e-04 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0278 - accuracy: 0.9960 - val_loss: 2.1958e-04 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0243 - accuracy: 0.9963 - val_loss: 3.3764e-04 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0212 - accuracy: 0.9967 - val_loss: 1.6702e-04 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0299 - accuracy: 0.9966 - val_loss: 6.2275e-04 - val_accuracy: 0.9999\n",
      "Epoch 496/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0186 - accuracy: 0.9973 - val_loss: 3.0063e-04 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0251 - accuracy: 0.9967 - val_loss: 4.0443e-05 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0245 - accuracy: 0.9968 - val_loss: 5.6785e-04 - val_accuracy: 0.9998\n",
      "Epoch 499/500\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0245 - accuracy: 0.9961 - val_loss: 5.0193e-04 - val_accuracy: 0.9999\n",
      "Epoch 500/500\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.0227 - accuracy: 0.9970 - val_loss: 4.1735e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f159ac0ded0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x,y,batch_size=64,epochs=500,validation_data=(x_test,y_test))\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:56:21.097340Z",
     "iopub.status.busy": "2020-09-06T16:56:21.096229Z",
     "iopub.status.idle": "2020-09-06T16:56:22.257473Z",
     "shell.execute_reply": "2020-09-06T16:56:22.256637Z"
    },
    "papermill": {
     "duration": 3.309759,
     "end_time": "2020-09-06T16:56:22.257628",
     "exception": false,
     "start_time": "2020-09-06T16:56:18.947869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(x1)\n",
    "pre=predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-06T16:56:26.486403Z",
     "iopub.status.busy": "2020-09-06T16:56:26.485739Z",
     "iopub.status.idle": "2020-09-06T16:56:26.797172Z",
     "shell.execute_reply": "2020-09-06T16:56:26.797663Z"
    },
    "papermill": {
     "duration": 2.433389,
     "end_time": "2020-09-06T16:56:26.797820",
     "exception": false,
     "start_time": "2020-09-06T16:56:24.364431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.Series(pre,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),submission],axis = 1)\n",
    "submission.to_csv(\"final_submission_v1.csv\",index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.280623,
     "end_time": "2020-09-06T16:56:31.040934",
     "exception": false,
     "start_time": "2020-09-06T16:56:28.760311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# END!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.934442,
     "end_time": "2020-09-06T16:56:34.977326",
     "exception": false,
     "start_time": "2020-09-06T16:56:33.042884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.282194,
     "end_time": "2020-09-06T16:56:39.269032",
     "exception": false,
     "start_time": "2020-09-06T16:56:36.986838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1945.640052,
   "end_time": "2020-09-06T16:56:42.724297",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-06T16:24:17.084245",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
